{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28790032cc8f8d67",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "9dbb94b41f3c164f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T15:23:56.230522Z",
     "start_time": "2025-06-15T15:23:56.226143Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "from Tools.leica_tools import LeicaHandler\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "import cv2\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T15:24:01.027450Z",
     "start_time": "2025-06-15T15:24:01.024958Z"
    }
   },
   "cell_type": "code",
   "source": "None or 1",
   "id": "bf65cc5859c1d22f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset generation",
   "id": "491dd5bb2f60fc13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T17:50:06.360015Z",
     "start_time": "2025-06-13T17:50:06.356203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def divide_frame(full_width, full_height, droplets, TILE=512, OVERLAP=0.2):\n",
    "\n",
    "    MARGIN = int(TILE * OVERLAP)\n",
    "    coords = []\n",
    "    elements = []\n",
    "\n",
    "    for y_min in range(0, full_height, TILE - MARGIN):\n",
    "        for x_min in range(0, full_width, TILE - MARGIN):\n",
    "            x_max = min(full_width, x_min + TILE)\n",
    "            y_max = min(full_height, y_min + TILE)\n",
    "\n",
    "\n",
    "            # select droplets that are fully contained\n",
    "            subset = droplets.query(f'x_min >= {x_min} & x_max < {x_max} & y_min >= {y_min} & y_max < {y_max}').copy()\n",
    "\n",
    "            if subset.empty:\n",
    "                continue\n",
    "            #transform coordinates of droplets bounding boxes into rel_xyxy\n",
    "            subset['x_min'] = (subset['x_min'] - x_min)/(x_max-x_min)\n",
    "            subset['x_max'] = (subset['x_max'] - x_min)/(x_max-x_min)\n",
    "            subset['y_min'] = (subset['y_min'] - y_min)/(y_max-y_min)\n",
    "            subset['y_max'] = (subset['y_max'] - y_min)/(y_max-y_min)\n",
    "\n",
    "            coords.append((x_min, y_min, x_max, y_max))\n",
    "            elements.append({\n",
    "                'bboxes': subset[['x_min', 'y_min', 'x_max', 'y_max']].values.tolist(),\n",
    "                'categories': subset['outlier'].astype(int).tolist(),\n",
    "            })\n",
    "\n",
    "    return coords, elements"
   ],
   "id": "4606dcadc8cdac48",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T14:30:24.408909Z",
     "start_time": "2025-06-13T14:22:04.079778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EXP_ID = 'NKIP_FA_066'\n",
    "OUTPUT_DIR = '/Users/fauberma/yolo_detection'\n",
    "FNAME_PREFIX = EXP_ID\n",
    "TILE_SIZE = 512\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, \"images\"), exist_ok=True)\n",
    "\n",
    "exp = Experiment(EXP_ID)\n",
    "droplet_df = exp.get_droplet_df()#.query('frameID < 3')\n",
    "frame_df = exp.frame_df\n",
    "annotations = {}\n",
    "tiles = {}\n",
    "\n",
    "for frameID, droplet_subset in tqdm(droplet_df.groupby('frameID'), desc=\"Processing frames\"):\n",
    "    frame, meta = exp.handler.get_frame(frameID)\n",
    "    frame = Image.fromarray((frame[0]/ 256).astype(np.uint8)).convert(\"L\")\n",
    "    coords, elements = divide_frame(frame.width, frame.height, droplet_subset)\n",
    "\n",
    "    for coord, element in zip(coords, elements):\n",
    "        x_min, y_min, x_max, y_max = coord\n",
    "        tileID = f\"{FNAME_PREFIX}_{frameID}_{x_min}_{y_min}\"\n",
    "\n",
    "        image_path = os.path.join(OUTPUT_DIR, \"images\", f'{tileID}.png')\n",
    "        if not os.path.exists(image_path):\n",
    "            frame.crop((x_min, y_min, x_max, y_max)).save(image_path)\n",
    "\n",
    "        annotations[tileID] = element\n",
    "        tiles[tileID] = {'coord': coord, 'width': x_max-x_min, 'height':y_max-y_min}\n",
    "\n",
    "\n",
    "\n",
    "# --- Save COCO-style annotations ---\n",
    "with open(os.path.join(OUTPUT_DIR, f\"{FNAME_PREFIX}_annotations.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"images\": tiles,\n",
    "        \"annotations\": annotations,\n",
    "    }, f, indent=2)"
   ],
   "id": "9720d58a8f535525",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 25/25 [08:19<00:00, 19.99s/it]\n"
     ]
    }
   ],
   "execution_count": 464
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "3a9099e460d8a725"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T17:55:28.140097Z",
     "start_time": "2025-06-13T17:55:28.134283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_coco_dataset(data_dir, annotation_files, img_size=(512, 512), batch_size=8):\n",
    "    data = {}\n",
    "    for annotation_file in annotation_files:\n",
    "        with open(os.path.join(data_dir, annotation_file), \"r\") as f:\n",
    "            data.update(json.load(f)['annotations'])\n",
    "\n",
    "    for key, val in data.items():\n",
    "        bboxes = val['bboxes']\n",
    "        for box in bboxes:\n",
    "            assert(len(box) == 4)\n",
    "    paths = [os.path.join(data_dir, 'images', f'{ID}.png') for ID in data.keys()]\n",
    "    bboxes = tf.ragged.constant([data[ID]['bboxes'] for ID in data.keys()], dtype=tf.float32, ragged_rank=1, inner_shape=(4,))\n",
    "    labels = tf.ragged.constant([data[ID]['categories'] for ID in data.keys()], dtype=tf.float32)\n",
    "\n",
    "    def load_sample(path, bbox, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_png(img, channels=3)\n",
    "        img = tf.image.resize(img, img_size)\n",
    "        img = tf.cast(img, tf.float32)\n",
    "\n",
    "        bounding_boxes = {\n",
    "            \"classes\": label,\n",
    "            \"boxes\": bbox,\n",
    "        }\n",
    "        return {\"images\": img, \"bounding_boxes\": bounding_boxes}\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, bboxes, labels))\n",
    "    ds.shuffle(buffer_size=ds.cardinality())\n",
    "    ds = ds.map(load_sample).ragged_batch(batch_size, drop_remainder=True)\n",
    "    return ds\n",
    "\n",
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]"
   ],
   "id": "701cae6db5952fc8",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T17:55:28.883810Z",
     "start_time": "2025-06-13T17:55:28.870795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "augmenter = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomShear(\n",
    "            x_factor=0.2, y_factor=0.2, bounding_box_format=\"rel_xyxy\"\n",
    "        ),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(512, 512), scale_factor=(0.4, 1.6), bounding_box_format=\"rel_xyxy\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ],
   "id": "37e1a96ea555104b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T17:55:34.395834Z",
     "start_time": "2025-06-13T17:55:31.028363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = load_coco_dataset(\n",
    "    data_dir=\"/Users/fauberma/yolo_detection\",\n",
    "    annotation_files=[\"NKIP_FA_082_annotations.json\", \"NKIP_FA_081_annotations.json\",\"NKIP_FA_070_annotations.json\",\"NKIP_FA_066_annotations.json\"],\n",
    "    img_size=(512, 512),\n",
    "    batch_size=8,\n",
    ")"
   ],
   "id": "67eefbd1915cd7e4",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T17:55:39.718878Z",
     "start_time": "2025-06-13T17:55:39.442262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_ds = ds.take(200)\n",
    "train_ds = ds.skip(200).take(1500)\n",
    "train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)"
   ],
   "id": "523ed6ac5ec66241",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T17:55:41.807485Z",
     "start_time": "2025-06-13T17:55:41.186340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "backbone = keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "    \"yolo_v8_s_backbone\"  # We will use yolov8 small backbone with coco weights\n",
    ")\n",
    "\n",
    "yolo = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=2,\n",
    "    bounding_box_format=\"rel_xyxy\",\n",
    "    backbone=backbone,\n",
    "    fpn_depth=1,\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    global_clipnorm=10.0,\n",
    ")\n",
    "\n",
    "yolo.compile(\n",
    "    optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\"\n",
    ")"
   ],
   "id": "ef79c551210ae384",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T18:17:45.394775Z",
     "start_time": "2025-06-13T17:55:52.414339Z"
    }
   },
   "cell_type": "code",
   "source": "yolo.fit(train_ds, steps_per_epoch=500, validation_data=val_ds, epochs=3,)",
   "id": "fa1369a0238d7191",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 19:56:04.085529: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:933] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/RaggedSplit/assert_equal_3/Assert/AssertGuard/branch_executed/_733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 787ms/step - box_loss: 1.4839 - class_loss: 7.3051 - loss: 8.7890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 20:03:15.489658: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:933] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/RaggedSplit/assert_equal_3/Assert/AssertGuard/branch_executed/_341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m477s\u001B[0m 857ms/step - box_loss: 1.4833 - class_loss: 7.2957 - loss: 8.7790 - val_box_loss: 2.3946 - val_class_loss: 0.8728 - val_loss: 3.2674\n",
      "Epoch 2/3\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m414s\u001B[0m 829ms/step - box_loss: 0.9471 - class_loss: 0.5957 - loss: 1.5428 - val_box_loss: 1.1263 - val_class_loss: 0.6033 - val_loss: 1.7296\n",
      "Epoch 3/3\n",
      "\u001B[1m500/500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m422s\u001B[0m 843ms/step - box_loss: 0.8363 - class_loss: 0.4605 - loss: 1.2968 - val_box_loss: 0.9168 - val_class_loss: 0.4339 - val_loss: 1.3507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x617964b50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T17:25:23.720760Z",
     "start_time": "2025-06-13T17:25:23.463995Z"
    }
   },
   "cell_type": "code",
   "source": "yolo.save(os.path.join(os.getenv('MODEL_DIR'),'droplet_detection', 'yolo_v8_s_backbone_v3.keras'))",
   "id": "96ad0a1b8fca7d6",
   "outputs": [],
   "execution_count": 516
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a71dc6cf0ea76d72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
