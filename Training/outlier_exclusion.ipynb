{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c817509be757d53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from Tools.leica_tools import RawLoader\n",
    "from Tools.db_tools import DbManager\n",
    "from functools import partial\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from keras.api.models import Model\n",
    "from keras.api.layers import Input, Conv2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from keras.api.losses import BinaryCrossentropy\n",
    "from keras.api.metrics import BinaryAccuracy\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.utils import plot_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bb86d62ebc32413"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7ae77287f8a69b1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KMeans detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69fd6f744e4b5275"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expID = 'NKIP_FA_056'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78e968be5c623b5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rawloader = RawLoader(expID)\n",
    "dbm = DbManager()\n",
    "drop_register = rawloader.get_dropregister()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddd8cce1976de047"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds, spec = dbm.get_dataset(expID, return_spec=True)\n",
    "bins = 256\n",
    "histograms = np.zeros((spec['n_frames'], bins))\n",
    "globalIDs = np.zeros(spec['n_frames'])\n",
    "for i, element in enumerate(ds.as_numpy_iterator()):\n",
    "    globalIDs[i] = element['GlobalID']\n",
    "    frame = element['frame']\n",
    "    hist, bins = np.histogram(frame[:, :, 0].flatten(), bins=bins, range=(0, 65535), density=True)\n",
    "    histograms[i, :] = hist / np.sum(hist)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c682f113c34e67d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(histograms)\n",
    "cluster_labels, counts = np.unique(clusters, return_counts=True)\n",
    "for l, c in zip(cluster_labels, counts):\n",
    "    print(f'Group {l} labeled with {c} droplets')\n",
    "cluster_df =  pd.DataFrame(clusters, index=pd.Index(globalIDs, name='GlobalID').astype(int), columns=['cluster'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17b8a30711f769ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "with PdfPages(os.path.join(rawloader.an_dir, 'KMeans', f'KMeans_{n_clusters}c.pdf')) as pdf:\n",
    "    for c in cluster_labels:\n",
    "        fig, axs = plt.subplots(figsize=(4,4), ncols=4, nrows=4)\n",
    "        IDs = cluster_df.query(f'cluster == {c}').sample(16).index\n",
    "        frames = dbm.filter_db(expID, IDs)[:, :, :, 0]\n",
    "        for i, ax in enumerate(axs.flatten()):\n",
    "            ax.imshow(frames[i]/65535, cmap='gray', vmin=0, vmax=1)\n",
    "            ax.grid(False)\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "        fig.suptitle(f'Samples of cluster {c}', fontsize=15)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cf05cf62b6ca8eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_df['outlier_KMeans'] = False\n",
    "cluster_df.loc[cluster_df.query('cluster == 0 | cluster == 2 | cluster == 7').index, 'outlier_KMeans'] = True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4da7184edb52ca71"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rawloader.update_dropregister(drop_register.join(cluster_df))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17f9c24faeacfed0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "14e8adb9a975c0ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f216efb50d3b9bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dbm = DbManager()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b466c49dd248454d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def outlier_class():\n",
    "    inputs = Input(shape=(128,128,1), name='outlier_input')\n",
    "    \n",
    "    # Add convolutional layer\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', name='outlier_conv1')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), name='outlier_pool1')(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', name='outlier_conv2')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), name='outlier_pool2')(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', name='outlier_conv3')(pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), name='outlier_pool3')(conv3)\n",
    "    \n",
    "    # Flatten the output from the convolutional layers\n",
    "    flatten = Flatten(name='outlier_flatten')(pool3)\n",
    "    \n",
    "    # Add fully connected layers\n",
    "    dense1 = Dense(512, activation='relu', name='outlier_dense1')(flatten)\n",
    "    dropout1 = Dropout(0.5, name='outlier_dropout1')(dense1)  # Dropout rate of 0.5 (50% dropout rate)\n",
    "    \n",
    "    dense2 = Dense(256, activation='relu', name='outlier_dense2')(dropout1)\n",
    "    dropout2 = Dropout(0.5, name='outlier_dropout2')(dense2)  # Dropout rate of 0.5 (50% dropout rate)\n",
    "    \n",
    "    dense3 = Dense(128, activation='relu', name='outlier_dense3')(dropout2)\n",
    "    dropout3 = Dropout(0.5, name='outlier_dropout3')(dense3)  # Dropout rate of 0.5 (50% dropout rate)\n",
    "    \n",
    "    output = Dense(2, activation='softmax', name='outlier_output')(dropout3)  # Binary classification with sigmoid activation\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output, name='outlier_model')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e532e65387e45435"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_data(element, outlier_data):\n",
    "    globalID = element['GlobalID']\n",
    "    expID = element['expID']\n",
    "    element['outlier_input'] = tf.cast(element['frame'][:, :, tf.constant(0)], tf.float32) / 65535\n",
    "    \n",
    "    outputs = {}\n",
    "    label = tf.py_function(lambda x, i: outlier_data.loc[(x.numpy().decode(), i.numpy()), 'outlier_KMeans'], [expID, globalID], tf.int64)\n",
    "    label.set_shape(())\n",
    "    label = tf.cast(tf.one_hot(label, 2), tf.int64)\n",
    "    outputs['outlier_output'] = label\n",
    "    return element, outputs\n",
    "\n",
    "def build_dataset(expIDs):\n",
    "    dataset = dbm.get_datasets(expIDs, shuffle=True)\n",
    "\n",
    "    outlier_dfs = []\n",
    "    for expID in expIDs:\n",
    "        drop_register = RawLoader(expID).get_dropregister()\n",
    "        outlier_df = drop_register[['outlier_KMeans',]].copy()\n",
    "        outlier_df.set_index(pd.MultiIndex.from_product([[expID], outlier_df.index]), inplace=True)  \n",
    "        outlier_dfs.append(outlier_df)\n",
    "    outlier_df = pd.concat(outlier_dfs)\n",
    "\n",
    "    annotated_dataset = dataset.map(partial(prepare_data, outlier_data=outlier_df))\n",
    "    return annotated_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f781b1285b39f39c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expIDs = ['NKIP_FA_052','NKIP_FA_053', 'NKIP_FA_055', 'NKIP_FA_056']\n",
    "dataset = build_dataset(expIDs)\n",
    "validation_dataset = build_dataset(['NKIP_FA_051'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49b919de6c229c08"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_elements = dataset.reduce(tf.constant(0), lambda a,b: a+1).numpy()\n",
    "n_elements_val = validation_dataset.reduce(tf.constant(0), lambda a,b: a+1).numpy()\n",
    "print(f'{n_elements} frames in train dataset')\n",
    "print(f'{n_elements_val} frames in test dataset')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc9bb097ab8fa226"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_final = dataset.shuffle(15000).repeat(2).batch(32)\n",
    "test_final = validation_dataset.repeat(2).batch(32)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "504c438ed809a3b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = outlier_class()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1a907e707f7b7dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_arch = plot_model(model, to_file='outlier_exclusion.png', dpi=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a959080bf498668d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(),\n",
    "              loss={'outlier_output': BinaryCrossentropy()},\n",
    "              metrics={'outlier_output': BinaryAccuracy()})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ba34d593d864d2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(train_final, validation_data=test_final, batch_size=32, steps_per_epoch=16089, epochs=2, validation_steps=4701)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2714bcd47cd7a4bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(os.path.join(config['MODEL_DIR'], 'outlier_v2.h5'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3edd584400b82f05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to normalize your data\n",
    "def prepare_data(element, outlier_df):\n",
    "    globalID = element['GlobalID']  # Assuming 'GlobalID' is a tensor\n",
    "    expID = element['expID']\n",
    "    frame = tf.cast(element['frame'][:, :, tf.constant(0)], tf.float32) / 65535\n",
    "\n",
    "    #label = tf.py_function(lambda x: outlier_vec.get(x.numpy()), [globalID], tf.int64)\n",
    "    label = tf.py_function(lambda x, i: outlier_df.loc[(x.numpy().decode(), i.numpy()), 'outlier_KMeans'], [expID, globalID], tf.int64)\n",
    "    label.set_shape(())\n",
    "    label = tf.cast(tf.one_hot(label, 2), tf.int64)\n",
    "    element['outlier_output'] = label\n",
    "    element['outlier_input'] = frame\n",
    "    return element, element\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "415fff4d6e04febc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_data(expID):\n",
    "    rawloader = RawLoader(expID)\n",
    "    drop_register = rawloader.get_dropregister()\n",
    "    outlier_df = drop_register[['outlier_KMeans',]].copy().reset_index()\n",
    "    outlier_df['expID'] = expID\n",
    "    outlier_df.set_index(['expID', 'GlobalID'], inplace=True)\n",
    "    dataset = dbm.get_dataset(expID)\n",
    "    return dataset, outlier_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65cac676efdc9eb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f3ea94a8c77809b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7773f05c69a9d5c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expID = 'AT_2024_007'\n",
    "rawloader = RawLoader(expID)\n",
    "drop_register = rawloader.get_dropregister()\n",
    "label_dict = drop_register['outlier'].to_dict()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76260aa75a96b732"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = dbm.get_dataset(expID)\n",
    "normalized_dataset = dataset.map(partial(normalize, label_dict=label_dict)).batch(32)\n",
    "y_predict_raw = model.predict(normalized_dataset)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "324ae77a88f373a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "globalIDs = [e['GlobalID'] for e in dataset.as_numpy_iterator()]\n",
    "y_predict = np.argmax(y_predict_raw,axis=1).astype(bool)\n",
    "drop_register.loc[globalIDs, 'outlier'] = y_predict\n",
    "rawloader.update_dropregister(drop_register)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd0f1bd07b3ff79d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59fd680109baeb1c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(rawloader.an_dir, 'outlier_summary.pdf')) as pdf:\n",
    "    for outlier in [True, False]:\n",
    "        fig, axs = plt.subplots(figsize=(8,8), ncols=8, nrows=8)\n",
    "        subset = drop_register.query(f'outlier == {outlier}').copy()\n",
    "        size = subset.index.size\n",
    "        IDs = subset.sample(min(size,64)).index\n",
    "        frames = dbm.filter_db(expID, IDs)[:, :, :, 0]\n",
    "        for i, ax in enumerate(axs.flatten()):\n",
    "            ax.imshow(frames[i]/65535, cmap='gray', vmin=0, vmax=1)\n",
    "            ax.grid(False)\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "        if outlier:\n",
    "            fig.suptitle(f'Samples of detected outliers ({size} in total)', fontsize=15)\n",
    "        else:\n",
    "            fig.suptitle(f'Samples of detected non-outliers ({size} in total)', fontsize=15)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0ecfe2610becb6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed6b46039b394a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
